{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "77f48557-fead-470a-8614-4bb13f185177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v4a import *\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5095ea64-e035-466d-8665-04199f103e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    directory  = os.getcwd()\n",
    "    train_dataset = h5py.File('.\\\\datasets\\\\train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('.\\\\datasets\\\\test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46412f06-be26-4cb0-ad58-243e5fdd1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig , train_set_y_orig, test_set_x_orig, test_set_y_orig, classes  = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9eaeae6c-c2c9-40bc-8ac6-c3b334619864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of training examples m_train  209\n",
      "no of training examples m_test  50\n",
      "image pixel height =  64 image pixel width  =  64\n",
      "(209, 64, 64, 3)\n",
      "(1, 209)\n",
      "(50, 64, 64, 3)\n",
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "m  = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "height,width = train_set_x_orig.shape[1:3]\n",
    "print(\"no of training examples m_train \" , m)\n",
    "print(\"no of training examples m_test \" ,m_test)\n",
    "print(\"image pixel height = \", height, \"image pixel width  = \", width)\n",
    "print(train_set_x_orig.shape)\n",
    "print(train_set_y_orig.shape)\n",
    "print(test_set_x_orig.shape)\n",
    "print(test_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80ea5c70-a5e9-4973-9ae6-e81477b00d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 50)\n",
      "(12288, 209)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_set_x_flatten = np.transpose(np.reshape(train_set_x_orig,(m_train, -1)))   #can use both methods\n",
    "train_set_x_flatten = train_set_x_orig.reshape(m, -1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(m_test, -1).T\n",
    "print(test_set_x_flatten.shape)\n",
    "print(train_set_x_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "663781d5-d091-45e6-b633-5c04f6606c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209)\n",
      "(12288, 50)\n",
      "(1, 209)\n"
     ]
    }
   ],
   "source": [
    "#intializing variables\n",
    "train_set_x = train_set_x_flatten/255\n",
    "test_set_x = test_set_x_flatten/255\n",
    "print(train_set_x.shape)\n",
    "print(test_set_x.shape)\n",
    "print(train_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e42c7c21-6cca-40d9-9bf0-d096cd110f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "\n",
    "    for l in range(1,L):\n",
    "        parameters['w' + str(l)] = np.random.randn(layer_dims[l-1], layer_dims[l])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "\n",
    "        assert(parameters['w' + str(l)].shape == (layer_dims[l-1], layer_dims[l]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e125946-64b0-4fc4-96cb-d4a6bfeb96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(a, w, b):\n",
    "    z = np.dot(w.T , a) +b\n",
    "    assert(z.shape == (w.shape[1], a.shape[1]))\n",
    "    cache = (a, w, b)\n",
    "    return z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "776b2472-e456-4c3b-b0ef-9a1985489242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(a_prev, w, b, activation):\n",
    "    if (activation==\"sigmoid\"):\n",
    "        z , linear_cache = linear_forward(a_prev, w, b)\n",
    "        a, activation_cache= sigmoid(z)\n",
    "\n",
    "\n",
    "    if (activation ==\"relu\"):\n",
    "        z , linear_cache = linear_forward(a_prev , w, b)\n",
    "        a , activation_cache = relu(z)\n",
    "\n",
    "    assert(a.shape == (w.shape[1], a_prev.shape[1]))\n",
    "    cache = (linear_cache , activation_cache)\n",
    "    return a, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d796a4a1-7686-42b0-91ac-52b9bdc163a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "\n",
    "    a  = X\n",
    "    l = len(parameters) // 2 \n",
    "    # no of layers = l\n",
    "\n",
    "    for i in range(1 , l):\n",
    "        a_prev = a\n",
    "        a , linear_activation_cache= linear_activation_forward(a_prev, parameters[\"w\"+str(i)] , parameters[\"b\"+str(i)] , activation =  \"relu\")\n",
    "        caches.append(linear_activation_cache)\n",
    "    al , linear_activation_cache = linear_activation_forward(a, parameters['w' + str(l)] , parameters['b' + str(l)] ,activation =  \"sigmoid\")\n",
    "    caches.append(linear_activation_cache)    \n",
    "    return al, caches                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3877da50-a759-4146-bfb7-d3931dd5e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cost(AL, Y):\n",
    "#     \"\"\"\n",
    "#     Implement the cost function defined by equation (7).\n",
    "\n",
    "#     Arguments:\n",
    "#     AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "#     Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "#     Returns:\n",
    "#     cost -- cross-entropy cost\n",
    "#     \"\"\"\n",
    "    \n",
    "#     m = Y.shape[1]\n",
    "\n",
    "#     # Compute loss from aL and y.\n",
    "#     ### START CODE HERE ### (≈ 1 lines of code)\n",
    "#     cost = (-1/m) * (np.dot(Y, np.log(AL).T) + np.dot((1-Y), np.log(1-AL).T))\n",
    "#     ### END CODE HERE ###\n",
    "    \n",
    "#     cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "#     assert(cost.shape == ())\n",
    "    \n",
    "#     return cost\n",
    "\n",
    "def compute_cost(al, y):\n",
    "    m = y.shape[1]\n",
    "    cost = (-1/m) *(np.dot(y, np.log(al).T) + np.dot((1-y) , np.log(1-al).T))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80bb3ee8-2239-4750-9efe-839a170eac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dz , cache):\n",
    "    a_prev, w, b = cache\n",
    "\n",
    "    dw = np.dot(a_prev , dz.T)/m\n",
    "    db = np.sum(dz, axis = 1, keepdims = True)/m\n",
    "    da_prev =  np.dot(w , dz)\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(da_prev.shape == (w.shape[0] , dz.shape[1]))\n",
    "\n",
    "    return da_prev , dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6621f210-7275-4db8-afc8-2fc5ab9e80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(da, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation ==\"relu\":\n",
    "        dz = relu_backward(da , activation_cache)\n",
    "\n",
    "    elif activation== \"sigmoid\":\n",
    "        dz = sigmoid_backward(da, activation_cache)\n",
    "\n",
    "    da_prev , dw , db = linear_backward(dz, linear_cache)\n",
    "    return da_prev , dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c8806df-194f-45c5-b04d-5b51afe94206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(al, y, caches):\n",
    "    grads = {}\n",
    "    l = len(caches)\n",
    "    # y = y.reshape(al.shape)\n",
    "    dal = - (np.divide(y, al) - np.divide(1 - y, 1 - al))\n",
    "    current_cache = caches[l-1]\n",
    "    da_prev , grads[\"dw\" + str(l)] , grads[\"db\" + str(l)] = linear_activation_backward(dal, current_cache, \"sigmoid\")\n",
    "    \n",
    "    for i in reversed(range(l-1)):\n",
    "        current_cache = caches[i]\n",
    "        da_prev , grads[\"dw\" + str(i+1)] , grads[\"db\" + str(i+1)] = linear_activation_backward(da_prev, current_cache, \"relu\")\n",
    "\n",
    "    # del grads[\"da0\"]\n",
    "    return grads\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa694891-ff23-4034-8851-c5d6693800ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)] - learning_rate * grads[\"dw\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d79140d7-bd01-45fa-8471-fb9b1195b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X , y  , learning_rate, num_iterations):\n",
    "    costs = []\n",
    "    n1 = X.shape[0]\n",
    "    parameters = initialize_parameters_deep([n1 , 10, 10 ,1])\n",
    "    for i in range(num_iterations):\n",
    "        al , caches = L_model_forward(X , parameters)\n",
    "        grads = L_model_backward(al, y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if(i%1000 ==0):\n",
    "            cost = compute_cost(al,y)\n",
    "            costs.append(cost)\n",
    "            print(cost)\n",
    "\n",
    "\n",
    "    yhat, lol  = L_model_forward(X , parameters)\n",
    "    return yhat, costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8bdf81ba-d78e-4c8d-a542-8bd609225933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931941002879829\n",
      "0.6437837520082831\n",
      "0.3952333403556931\n",
      "0.5778733670216784\n",
      "0.2801036388117088\n",
      "0.27095512160812296\n",
      "0.264875730306688\n",
      "0.26487146709293\n",
      "0.26487100193197294\n",
      "0.2648690189692065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(0.6931941),\n",
       " array(0.64378375),\n",
       " array(0.39523334),\n",
       " array(0.57787337),\n",
       " array(0.28010364),\n",
       " array(0.27095512),\n",
       " array(0.26487573),\n",
       " array(0.26487147),\n",
       " array(0.264871),\n",
       " array(0.26486902)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_set_x , train_set_y_orig, 0.075 ,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25ac7acc-4f0b-4c8f-b6fa-b097b62f971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693049587856763\n",
      "0.11036148903592287\n",
      "0.02798814246460389\n",
      "0.0012937789069067383\n",
      "0.0005410914226593582\n",
      "0.00032460144205136393\n",
      "0.00022635313478315856\n",
      "0.0001714156641596063\n",
      "0.00013674790660148995\n",
      "0.00011307286407014483\n",
      "accuracy  100.0\n",
      "final cost  0.00011307286407014483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict(X ,y):\n",
    "    m = X.shape[1]\n",
    "    yhat , costs = model(X , y, 0.075 ,10000)\n",
    "    value =  yhat>0.5\n",
    "    accuracy = 100* np.sum(1 - np.logical_xor(value, y))/m \n",
    "    print(\"accuracy \" , accuracy)\n",
    "    print(\"final cost \" , costs[-1])\n",
    "    return 0\n",
    "    \n",
    "\n",
    "predict(test_set_x , test_set_y_orig)\n",
    "# print(value.shape)\n",
    "# print(Y.shape)\n",
    "# print(value[0,:10])\n",
    "# value = 1-value\n",
    "# print(value[0,:10])\n",
    "\n",
    "# accuracy = 100*(np.sum(value * Y) + np.sum((1-value)*(1-Y)))*1/(m)\n",
    "\n",
    "# accuracy = 100* np.sum(1 - np.logical_xor(value, Y))/m              #faster probably \n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7edf8f-f0f8-4523-8138-61c785d4dcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
